{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Objective:\n",
    "Learn how to explore built-in datasets in Scikit-learn.\n",
    "\n",
    "Understand and compare classification models.\n",
    "\n",
    "Practice model evaluation with accuracy, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì¶ Step 1: Choose a Dataset\n",
    "Scikit-learn has several toy datasets. Choose one from the list below:\n",
    "\n",
    "\n",
    "load_wine\n",
    "\n",
    "load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# your code to load the dataset\n",
    "# Load the dataset\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# Features and target\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "print(\"Dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîç Step 2: Explore the Dataset\n",
    "Answer these:\n",
    "\n",
    "1. How many samples and features are there?\n",
    "\n",
    "2. What are the feature names?\n",
    "\n",
    "3. What are the target classes?\n",
    "\n",
    "4. What are the dimensions of the dataset\n",
    "\n",
    "5. is Scaling/Normalisation needed for our dataset and what is the difference \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1797\n",
      "Number of features: 64\n",
      "Feature names: ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
      "Target classes: [0 1 2 3 4 5 6 7 8 9]\n",
      "Dataset dimensions: (1797, 64)\n",
      "Feature range (min, max): (0.0, 16.0)\n"
     ]
    }
   ],
   "source": [
    "# your code to explore the dataset\n",
    "# Explore the dataset\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Feature names: {digits.feature_names if hasattr(digits, 'feature_names') else 'Not available'}\")\n",
    "print(f\"Target classes: {digits.target_names}\")\n",
    "print(f\"Dataset dimensions: {X.shape}\")\n",
    "\n",
    "# Check if scaling/normalization is needed\n",
    "print(f\"Feature range (min, max): ({X.min()}, {X.max()})\")\n",
    "#\"Scaling is recommended for models sensitive to feature magnitudes (e.g., SVM).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Based on the insights you gained from the previous step perform any necessary preprocessing if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled successfully.\n"
     ]
    }
   ],
   "source": [
    "# Your preprocessing steps\n",
    "# Preprocessing: Scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Features scaled successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Build and Train a Model\n",
    "Use a classification model (your choice ‚Äî try more than one):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "Split the data using train_test_split()\n",
    "\n",
    "Train your model\n",
    "\n",
    "Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# explore and experiment with different models!\n",
    "# provide a brief description of each model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "# Train models\n",
    "log_reg.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Models trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìä Step 4: Evaluate the Model\n",
    "Use the following metrics to evaluate your classifier:\n",
    "\n",
    "accuracy_score\n",
    "\n",
    "confusion_matrix\n",
    "\n",
    "classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.9722222222222222\n",
      "Confusion Matrix:\n",
      "[[33  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 33  0  1  0  0  0  0]\n",
      " [ 0  1  0  0 45  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 44  1  0  0  2]\n",
      " [ 0  0  0  0  0  1 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 33  0  1]\n",
      " [ 0  0  0  0  0  1  0  0 29  0]\n",
      " [ 0  0  0  1  0  0  0  0  1 38]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       0.97      1.00      0.98        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       0.97      0.97      0.97        34\n",
      "           4       1.00      0.98      0.99        46\n",
      "           5       0.94      0.94      0.94        47\n",
      "           6       0.97      0.97      0.97        35\n",
      "           7       1.00      0.97      0.99        34\n",
      "           8       0.97      0.97      0.97        30\n",
      "           9       0.93      0.95      0.94        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.85\n",
      "Confusion Matrix:\n",
      "[[29  0  0  0  2  1  0  0  0  1]\n",
      " [ 0 22  1  0  2  0  0  1  1  1]\n",
      " [ 0  1 25  2  2  0  1  1  1  0]\n",
      " [ 0  0  1 28  0  1  0  1  1  2]\n",
      " [ 0  0  0  0 42  2  0  2  0  0]\n",
      " [ 0  0  0  1  1 44  1  0  0  0]\n",
      " [ 0  0  0  0  2  0 33  0  0  0]\n",
      " [ 0  0  0  2  2  1  0 29  0  0]\n",
      " [ 0  3  1  1  1  1  0  0 21  2]\n",
      " [ 0  1  0  2  3  1  0  0  0 33]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        33\n",
      "           1       0.81      0.79      0.80        28\n",
      "           2       0.89      0.76      0.82        33\n",
      "           3       0.78      0.82      0.80        34\n",
      "           4       0.74      0.91      0.82        46\n",
      "           5       0.86      0.94      0.90        47\n",
      "           6       0.94      0.94      0.94        35\n",
      "           7       0.85      0.85      0.85        34\n",
      "           8       0.88      0.70      0.78        30\n",
      "           9       0.85      0.82      0.84        40\n",
      "\n",
      "    accuracy                           0.85       360\n",
      "   macro avg       0.86      0.84      0.85       360\n",
      "weighted avg       0.86      0.85      0.85       360\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.9666666666666667\n",
      "Confusion Matrix:\n",
      "[[32  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 32  0  1  0  0  1  0]\n",
      " [ 0  0  0  0 46  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 45  1  0  0  1]\n",
      " [ 0  0  0  0  0  1 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 33  0  1]\n",
      " [ 0  2  0  0  0  1  0  0 27  0]\n",
      " [ 0  0  0  0  0  1  0  1  0 38]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.93      1.00      0.97        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.94      0.97        34\n",
      "           4       0.98      1.00      0.99        46\n",
      "           5       0.92      0.96      0.94        47\n",
      "           6       0.97      0.97      0.97        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       0.96      0.90      0.93        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "\n",
      "Support Vector Classifier:\n",
      "Accuracy: 0.9805555555555555\n",
      "Confusion Matrix:\n",
      "[[33  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 33  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 46  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 46  1  0  0  0]\n",
      " [ 0  0  0  0  0  0 35  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 32  0  1]\n",
      " [ 0  0  0  0  1  0  0  0 29  0]\n",
      " [ 0  0  0  0  0  1  0  0  1 38]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.97      0.99        34\n",
      "           4       0.96      1.00      0.98        46\n",
      "           5       0.96      0.98      0.97        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       1.00      0.94      0.97        34\n",
      "           8       0.97      0.97      0.97        30\n",
      "           9       0.97      0.95      0.96        40\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "log_reg_preds = log_reg.predict(X_test)\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, log_reg_preds)}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, log_reg_preds))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, log_reg_preds))\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "decision_tree_preds = decision_tree.predict(X_test)\n",
    "print(\"\\nDecision Tree:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, decision_tree_preds)}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, decision_tree_preds))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, decision_tree_preds))\n",
    "\n",
    "# Evaluate Random Forest\n",
    "random_forest_preds = random_forest.predict(X_test)\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, random_forest_preds)}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, random_forest_preds))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, random_forest_preds))\n",
    "\n",
    "# Evaluate SVC\n",
    "svc_preds = svc.predict(X_test)\n",
    "print(\"\\nSupport Vector Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, svc_preds)}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, svc_preds))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, svc_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
